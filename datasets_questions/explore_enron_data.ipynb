{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starter code for exploring the Enron dataset (emails + finances);\n",
    "loads up the dataset (pickled dict of dicts).\n",
    "\n",
    "The dataset has the form:\n",
    "enron_data[\"LASTNAME FIRSTNAME MIDDLEINITIAL\"] = { features_dict }\n",
    "\n",
    "{features_dict} is a dictionary of features associated with that person.\n",
    "You should explore features_dict as part of the mini-project,\n",
    "but here's an example to get you started:\n",
    "\n",
    "enron_data[\"SKILLING JEFFREY K\"][\"bonus\"] = 5600000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_data = pickle.load(open(\"../final_project/final_project_dataset.pkl\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aggregated Enron email + financial dataset is stored in a dictionary, where each key in the dictionary is a person’s name and the value is a dictionary containing all the features of that person.\n",
    "The email + finance (E+F) data dictionary is stored as a pickle file, which is a handy way to store and load python objects directly. Use datasets_questions/explore_enron_data.py to load the dataset.\n",
    "\n",
    "## How many data points (people) are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n"
     ]
    }
   ],
   "source": [
    "print(len(enron_data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each person, how many features are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enron_data['ALLEN PHILLIP K'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The “poi” feature records whether the person is a person of interest, according to our definition. \n",
    "## How many POIs are there in the E+F dataset?\n",
    "\n",
    "In other words, count the number of entries in the dictionary where\n",
    "data[person_name][\"poi\"]==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person of Interest in E+F dataset\n"
     ]
    }
   ],
   "source": [
    "poi = sum([enron_data[person]['poi'] == 1 for person in enron_data.keys()])\n",
    "print('Person of Interest in E+F dataset'.format(poi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compiled a list of all POI names (in ../final_project/poi_names.txt) and associated email addresses (in ../final_project/poi_email_addresses.py).\n",
    "\n",
    "## How many POI’s were there total? \n",
    "\n",
    "(Use the names file, not the email addresses, since many folks have more than one address and a few didn’t work for Enron, so we don’t have their emails.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person of Interest: 35\n"
     ]
    }
   ],
   "source": [
    "filepath = '../final_project/poi_names.txt'\n",
    "with open(filepath) as file:\n",
    "    data = file.read()\n",
    "    data_list = data.split('\\n')\n",
    "    persons = data_list[2:-1]\n",
    "    poi = len(persons)\n",
    "    print('Person of Interest: {}'.format(poi))\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems with Incomplete data.\n",
    "\n",
    "As you can see, we have many of the POIs in our E+F dataset, but not all of them. \n",
    "\n",
    "## Why is that a potential problem?\n",
    "\n",
    "We will return to this later to explain how a POI could end up not being in the Enron E+F dataset, so you fully understand the issue before moving on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks for completing that!. There are a few things you could say here, but our main thought is about having enough data to really learn the patterns.  In general, more data is always better--only having 18 data points doesn't give you that many examples to learn from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the dataset 1\n",
    "\n",
    "Like any dict of dicts, individual people/features can be accessed like so:\n",
    "\n",
    "enron_data[\"LASTNAME FIRSTNAME\"][\"feature_name\"]\n",
    "or, sometimes \n",
    "enron_data[\"LASTNAME FIRSTNAME MIDDLEINITIAL\"][\"feature_name\"]\n",
    "\n",
    "What is the total value of the stock belonging to James Prentice?\n",
    "\n",
    "##### Notes:\n",
    "Lastname, Firstname and Middle Initial all in CAPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock value of James Prentice: 1095040\n"
     ]
    }
   ],
   "source": [
    "james_prentice_total_stock_value = enron_data['PRENTICE JAMES']['total_stock_value']\n",
    "print('Stock value of James Prentice: {}'.format(james_prentice_total_stock_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the dataset 2\n",
    "\n",
    "Like any dict of dicts, individual people/features can be accessed like so:\n",
    "\n",
    "enron_data[\"LASTNAME FIRSTNAME\"][\"feature_name\"]\n",
    "\n",
    "### How many email messages do we have from Wesley Colwell to persons of interest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data['COLWELL WESLEY']['from_this_person_to_poi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the dataset 3\n",
    "\n",
    "Like any dict of dicts, individual people/features can be accessed like so:\n",
    "\n",
    "enron_data[\"LASTNAME FIRSTNAME\"][\"feature_name\"]\n",
    "\n",
    "or\n",
    "\n",
    "enron_data[\"LASTNAME FIRSTNAME MIDDLEINITIAL\"][\"feature_name\"]\n",
    "\n",
    "### What’s the value of stock options exercised by Jeffrey K Skilling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19250000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data['SKILLING JEFFREY K']['exercised_stock_options']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research the Enron Fraud\n",
    "\n",
    "n the coming lessons, we’ll talk about how the best features are often motivated by our human understanding of the problem at hand. In this case, that means knowing a little about the story of the Enron fraud.\n",
    "\n",
    "If you have an hour and a half to spare, “Enron: The Smartest Guys in the Room” is a documentary that gives an amazing overview of the story. Alternatively, there are plenty of archival newspaper stories that chronicle the rise and fall of Enron.\n",
    "\n",
    "Which of these schemes was Enron not involved in?\n",
    "\n",
    "```\n",
    "a. selling assets to shell companies at the end of each month, and buying them back at the beginning of the next month to hide accounting losses\n",
    "b. causing electrical grid failures in California\n",
    "c. illegally obtained a government report that enabled them to corner the market on frozen concentrated orange juice futures\n",
    "d. conspiring to give a Saudi prince expedited American citizenship\n",
    "e. a plan in collaboration with Blockbuster movies to stream movies over the internet\n",
    "```\n",
    "\n",
    "Answer: c and d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who was the CEO of Enron during most of the time that fraud was being perpetrated?\n",
    "\n",
    "Answer: Jeffrey Skilling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enron Chairman\n",
    "\n",
    "## Who was of the Enron board of directors?\n",
    "\n",
    "Answer: Kenneth Lay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who was CFO (chief financial officer) of Enron during most of the time that fraud was going on?\n",
    "\n",
    "Answer: Andrew Fastow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfulfilled Features\n",
    "\n",
    "## For nearly every person in the dataset, not every feature has a value. How is it denoted when a feature doesn’t have a well-defined value?\n",
    "\n",
    "Answer: NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with Unfulfilled features\n",
    "\n",
    "## How many folks in this dataset have a quantified salary? What about a known email address?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of quantified salary: 95\n",
      "Number of known_email_address: 111\n"
     ]
    }
   ],
   "source": [
    "quantified_salaries = sum([person['salary'] != 'NaN' for person_name, person in enron_data.items()])\n",
    "known_email_address = sum([person['email_address'] != 'NaN' for person_name, person in enron_data.items()])\n",
    "print(\"Number of quantified salary: {}\".format(quantified_salaries))\n",
    "print(\"Number of known_email_address: {}\".format(known_email_address))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dict-to-array Conversion\n",
    "\n",
    "A python dictionary can’t be read directly into an sklearn classification or regression algorithm; instead, it needs a numpy array or a list of lists (each element of the list (itself a list) is a data point, and the elements of the smaller list are the features of that point).\n",
    "\n",
    "We’ve written some helper functions (featureFormat() and targetFeatureSplit() in tools/feature_format.py) that can take a list of feature names and the data dictionary, and return a numpy array.\n",
    "\n",
    "In the case when a feature does not have a value for a particular person, this function will also replace the feature value with 0 (zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mission POIs 1 (optional)\n",
    "\n",
    "As you saw a little while ago, not every POI has an entry in the dataset (e.g. Michael Krautz). That’s because the dataset was created using the financial data you can find in final_project/enron61702insiderpay.pdf, which is missing some POI’s (those absences propagated through to the final dataset). On the other hand, for many of these “missing” POI’s, we do have emails.\n",
    "\n",
    "While it would be straightforward to add these POI’s and their email information to the E+F dataset, and just put “NaN” for their financial information, this could introduce a subtle problem. You will walk through that here.\n",
    "\n",
    "## How many people in the E+F dataset (as it currently exists) have “NaN” for their total payments? What percentage of people in the dataset as a whole is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_people_with_nan_total_payments: 21\n",
      "total people: 146\n",
      "Percentage of people: 0\n"
     ]
    }
   ],
   "source": [
    "number_of_people_with_nan_total_payments = sum([person['total_payments'] == 'NaN' for person_names, person in enron_data.items()])\n",
    "print(\"number_of_people_with_nan_total_payments: {}\".format(number_of_people_with_nan_total_payments))\n",
    "\n",
    "people = len(enron_data.items())\n",
    "print('total people: {}'.format(people))\n",
    "print('Percentage of people: {}'.format(number_of_people_with_nan_total_payments/people))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##How many  POIs in the E+F dataset have “NaN” for their total payments? What percentage of POI’s as a whole is this?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
